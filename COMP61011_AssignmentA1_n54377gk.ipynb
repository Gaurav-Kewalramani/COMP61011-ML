{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Brief: Fundamentals of Numpy and Pandas for Machine Learning  \n",
    "\n",
    "## Deadline: 01 November 2024, 14:00 GMT\n",
    "\n",
    "## Number of marks available: 10\n",
    "\n",
    "In this practical, we will practice using numpy and pandas to implement the fundamentals of machine learning experiments such as data splitting and model training and evaluation. \n",
    "\n",
    "### Please READ the whole assignment first, before starting to work on it.\n",
    "\n",
    "### How and what to submit\n",
    "\n",
    "A. A **Jupyter Notebook** with the code in all the cells executed and outputs displayed.\n",
    "\n",
    "B. Name your Notebook **COM61011_AssignmentA1_XXXXXX.ipynb** where XXXXXX is your username such as such as abc18de. Example: `COM61011_AssignmentA1_abc18de.ipynb`\n",
    "\n",
    "C. Upload the Jupyter Notebook in B to Blackboard under the **Group A: Computing Assignment 1** submission area before the deadline. **There are two submissions: please pay close attention to submit to the right place!**\n",
    "\n",
    "D. **NO DATA UPLOAD**: Please do not upload the data files used in this Notebook. We have a copy already. \n",
    "\n",
    "\n",
    "### Assessment Criteria \n",
    "\n",
    "* Being able to use numpy and pandas to preprocess a dataset.\n",
    "\n",
    "* Being able to follow the steps involved in an end-to-end project in machine learning.\n",
    "\n",
    "* Be able to implement, from scratch, a linear model and train it using gradient descent.\n",
    "\n",
    "\n",
    "### Code quality and use of Python libraries\n",
    "When writing your code, you will find out that there are operations that are repeated at least twice. If your code is unreadable, we may not award marks for that section. Make sure to check the following:\n",
    "\n",
    "* Did you include Python functions to solve the question and avoid repeating code? \n",
    "* Did you comment your code to make it readable to others?\n",
    "\n",
    "**DO NOT USE scikit-learn for the questions on this assignment. You are meant to write Python code from scratch. Using scikit-learn for the questions on this assignment will give ZERO marks. No excuse will be accepted.**\n",
    "\n",
    "Furthermore, please try to avoid using any imports apart from the ones already provided in the Notebook. You can easily install all recommended modules for this assignment by running the following command in your terminal: `python -m pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "### Late submissions\n",
    "\n",
    "We follow Department's guidelines about late submissions, i.e., a deduction of 10% of the mark each 24 hours the work is late after the deadline. NO late submission will be marked one week after the deadline. Please read [this link](https://wiki.cs.manchester.ac.uk/index.php/UGHandbook23:Main#Late_Submission_of_Coursework_Penalty). \n",
    "\n",
    "### Use of unfair means \n",
    "\n",
    "**Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.** Please carefully read [what constitutes Unfair Means](https://documents.manchester.ac.uk/display.aspx?DocID=2870) if not sure. If you still have questions, please ask your Personal tutor or the Lecturers.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: regularised ridge regression and gradient descent\n",
    "\n",
    "Regularisation is a technique commonly used in Machine Learning to prevent overfitting. It consists on adding terms to the objective function such that the optimisation procedure avoids solutions that just learn the training data. Popular techniques for regularisation in Supervised Learning include [Lasso Regression](https://en.wikipedia.org/wiki/Lasso_(statistics)), [Ridge Regression](https://en.wikipedia.org/wiki/Tikhonov_regularization) and the [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization). \n",
    "\n",
    "Here we will build a Ridge Regression model, and implement equations to optimise the objective function using the update rules for gradient descent. You will use those update rules for making predictions on an energy use dataset.\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Let us start with a data set for training $\\mathcal{D} = \\{\\mathbf{y}, \\mathbf{X}\\}$, where the vector $\\mathbf{y}=[y_1, \\cdots, y_N]^{\\top}$ and $\\mathbf{X}$ is the design matrix from Lab 3, this is, \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{X} = \n",
    "                \\begin{bmatrix}\n",
    "                        1 & x_{1,1} & \\cdots & x_{1, D}\\\\\n",
    "                        1 & x_{2,1} & \\cdots & x_{2, D}\\\\\n",
    "                   \\vdots &  \\vdots\\\\\n",
    "                        1 & x_{N,1} & \\cdots & x_{N, D}\n",
    "                \\end{bmatrix}\n",
    "               = \n",
    "               \\begin{bmatrix}\n",
    "                      \\mathbf{x}_1^{\\top}\\\\\n",
    "                       \\mathbf{x}_2^{\\top}\\\\\n",
    "                          \\vdots\\\\\n",
    "                        \\mathbf{x}_N^{\\top}\n",
    "                \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Our predictive model is going to be a linear model\n",
    "\n",
    "$$ f(\\mathbf{x}_i) = \\mathbf{w}^{\\top}\\mathbf{x}_i,$$\n",
    "\n",
    "where $\\mathbf{w} = [w_0\\; w_1\\; \\cdots \\; w_D]^{\\top}$.\n",
    "\n",
    "The **objective function** we are going to use has the following form\n",
    "\n",
    "$$ E(\\mathbf{w}, \\lambda) = \\frac{1}{N}\\sum_{n=1}^N (y_n - f(\\mathbf{x}_n))^2 + \\frac{\\lambda}{2}\\sum_{j=0}^D w_j^2,$$\n",
    "\n",
    "where $\\lambda>0$ is known as the *regularisation* parameter.\n",
    "\n",
    "This objective function was studied in Lecture 3. \n",
    "\n",
    "The first term on the rhs is what we call the \"fitting\" term whereas the second term in the expression is the regularisation term. Given $\\lambda$, the two terms in the expression have different purposes. The first term is looking for a value of $\\mathbf{w}$ that leads the squared-errors to zero. While doing this, $\\mathbf{w}$ can take any value and lead to a solution that it is only good for the training data but perhaps not for the test data. The second term is regularising the behavior of the first term by driving the $\\mathbf{w}$ towards zero. By doing this, it restricts the possible set of values that $\\mathbf{w}$ might take according to the first term. The value that we use for $\\lambda$ will allow a compromise between a value of $\\mathbf{w}$ that exactly fits the data (first term) or a value of $\\mathbf{w}$ that does not grow too much (second term).\n",
    "\n",
    "This type of regularisation has different names: ridge regression, Tikhonov regularisation or $\\ell_2$ norm regularisation. \n",
    "\n",
    "### Optimising the objective function with respect to $\\mathbf{w}$\n",
    "\n",
    "There are two ways we can optimise the objective function with respect to $\\mathbf{w}$. The first one leads to a closed form expression for $\\mathbf{w}$ and the second one using an iterative optimisation procedure that updates the value of $\\mathbf{w}$ at each iteration by using the gradient of the objective function with respect to $\\mathbf{w}$,\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} - \\eta \\frac{d E(\\mathbf{w}, \\lambda)}{d\\mathbf{w}},\n",
    "$$\n",
    "where $\\eta$ is the *learning rate* parameter and $\\frac{d E(\\mathbf{w}, \\lambda)}{d\\mathbf{w}}$ is the gradient of the objective function.\n",
    "\n",
    "It can be shown (this is a question in the Exercise Sheet 3) that a closed-form expression for the optimal $\\mathbf{w}_*$ is given as\n",
    "\n",
    "\\begin{align*}            \n",
    "            \\mathbf{w}_*& = \\left(\\mathbf{X}^{\\top}\\mathbf{X} + \\frac{\\lambda N}   \n",
    "                                     {2}\\mathbf{I}\\right)^{-1}\\mathbf{X}^{\\top}\\mathbf{y}.\n",
    "\\end{align*}\n",
    "\n",
    "Alternatively, we can find an update equation for $\\mathbf{w}_{\\text{new}}$ using gradient descent leading to:\n",
    "\n",
    "\\begin{align*}\n",
    "   \\mathbf{w}_{\\text{new}} & = \\mathbf{w}_{\\text{old}} - \\eta \\frac{d E(\\mathbf{w}, \\lambda)}\n",
    "                              {d\\mathbf{w}},\\\\\n",
    "                           & = \\mathbf{w}_{\\text{old}} +  \\frac{2\\eta}{N}\\sum_{n=1}^N   \n",
    "                               \\left(y_n - \\mathbf{x}_n^{\\top}\\mathbf{w}_{\\text{old}}\\right)\\mathbf{x}_n  \n",
    "                       - \\eta\\lambda\\mathbf{w}_{\\text{old}}\\\\\n",
    "                           & = (1 - \\eta\\lambda)\\mathbf{w}_{\\text{old}} + \\frac{2\\eta}\n",
    "                               {N}\\sum_{n=1}^N   \n",
    "                               \\left(y_n - \\mathbf{x}_n^{\\top}\\mathbf{w}_{\\text{old}}\\right)\\mathbf{x}_n\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-set up: imports and random seed\n",
    "\n",
    "**Important: set a random seed below that corresponds to the last five digits of your student ID number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaurav kewalramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request, os, zipfile\n",
    "\n",
    "rng = np.random.default_rng(126543) # replace xxxxx with the last 5 digits of your student ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataset that we will be using is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), a popular repository for open source datasets for educational and research purposes. We are going to use ridge regression to predict the energy use of appliances in a low energy building. The dataset is available [here](https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction) with an [accompanying paper](https://www.sciencedirect.com/science/article/pii/S0378778816308970?via%3Dihub).\n",
    "\n",
    "We can view some of the rows in the dataset with the `.sample()` method, or print the first few rows with the `.head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "if not os.path.exists('./energydata_complete.csv'):\n",
    "    durl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
    "    save_path = \"./energydata_complete.csv\"\n",
    "    urllib.request.urlretrieve(durl, save_path)\n",
    "\n",
    "# # Read the data into a pandas dataframe\n",
    "energy_appliances_full = pd.read_csv('./energydata_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
       "0  2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.790000   \n",
       "1  2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.722500   \n",
       "2  2016-01-11 17:20:00          50      30  19.89  46.300000  19.2  44.626667   \n",
       "3  2016-01-11 17:30:00          50      40  19.89  46.066667  19.2  44.590000   \n",
       "4  2016-01-11 17:40:00          60      40  19.89  46.333333  19.2  44.530000   \n",
       "\n",
       "      T3       RH_3         T4  ...         T9   RH_9     T_out  Press_mm_hg  \\\n",
       "0  19.79  44.730000  19.000000  ...  17.033333  45.53  6.600000        733.5   \n",
       "1  19.79  44.790000  19.000000  ...  17.066667  45.56  6.483333        733.6   \n",
       "2  19.79  44.933333  18.926667  ...  17.000000  45.50  6.366667        733.7   \n",
       "3  19.79  45.000000  18.890000  ...  17.000000  45.40  6.250000        733.8   \n",
       "4  19.79  45.000000  18.890000  ...  17.000000  45.40  6.133333        733.9   \n",
       "\n",
       "   RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
       "0    92.0   7.000000   63.000000        5.3  13.275433  13.275433  \n",
       "1    92.0   6.666667   59.166667        5.2  18.606195  18.606195  \n",
       "2    92.0   6.333333   55.333333        5.1  28.642668  28.642668  \n",
       "3    92.0   6.000000   51.500000        5.0  45.410389  45.410389  \n",
       "4    92.0   5.666667   47.666667        4.9  10.084097  10.084097  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View 5 random rows of the data\n",
    "energy_appliances_full.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the column headings are are printed below:\n",
    "\n",
    "| Data variables | Units |\n",
    "|----------------|-------|\n",
    "Date time stamp year-month-day | hour:min:s\n",
    "| Appliances energy consumption | Wh |\n",
    "| Light energy consumption | Wh | \n",
    "| T1, Temperature in kitchen area | ◦C | \n",
    "| RH1, Humidity in kitchen area | % | \n",
    "| T2, Temperature in living room area | ◦C | \n",
    "| RH2, Humidity in living room area | % | \n",
    "T3, Temperature in laundry room area | ◦C \n",
    "RH3, Humidity in laundry room area | % \n",
    "T4, Temperature in office room | ◦C \n",
    "RH4, Humidity in office room | % \n",
    "T5, Temperature in bathroom | ◦C \n",
    "RH5, Humidity in bathroom | % \n",
    "T6, Temperature outside the building (north side) | ◦C \n",
    "RH6, Humidity outside the building (north side) | % \n",
    "T7, Temperature in ironing room | ◦C \n",
    "RH7, Humidity in ironing room | % \n",
    "T8, Temperature in teenager room 2 | ◦C \n",
    "RH8, Humidity in teenager room 2 | % \n",
    "T9, Temperature in parents room | ◦C \n",
    "RH9, Humidity in parents room | % \n",
    "To, Temperature outside (from Chièvres weather station) | ◦C \n",
    "Pressure (from Chièvres weather station) | mm Hg \n",
    "RHo, Humidity outside (from Chièvres weather station) | % \n",
    "Windspeed (from Chièvres weather station) | m/s \n",
    "Visibility (from Chièvres weather station) | km \n",
    "Tdewpoint (from Chièvres weather station) | ◦C \n",
    "Random Variable 1 (RV 1) | Non dimensional\n",
    "Random Variable 2 (RV 2) | Non dimensional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first perform some minor data cleaning. \n",
    "\n",
    "We can't use `datetime` directly, since it's not a number, and encoding it as a continuous variable also creates issues. So let's try to extract some information from it that we can use. In this case, we'll use a binary variable to encode whether the day is a weekday or weekend. These are called categorical or dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>is_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>21.50</td>\n",
       "      <td>39.700000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>22.20</td>\n",
       "      <td>37.790000</td>\n",
       "      <td>20.463333</td>\n",
       "      <td>36.863333</td>\n",
       "      <td>...</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>41.925000</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>756.100000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>17.39</td>\n",
       "      <td>36.966667</td>\n",
       "      <td>16.390000</td>\n",
       "      <td>36.933333</td>\n",
       "      <td>17.79</td>\n",
       "      <td>37.290000</td>\n",
       "      <td>16.290000</td>\n",
       "      <td>36.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.429444</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>35.626667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>760.500000</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>-1.450000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>21.20</td>\n",
       "      <td>38.090000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>38.790000</td>\n",
       "      <td>20.89</td>\n",
       "      <td>39.530000</td>\n",
       "      <td>19.390000</td>\n",
       "      <td>39.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>41.090000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>90.833333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>23.166667</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19094</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>47.790000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>25.60</td>\n",
       "      <td>42.700000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.060000</td>\n",
       "      <td>23.290000</td>\n",
       "      <td>49.792857</td>\n",
       "      <td>11.233333</td>\n",
       "      <td>754.200000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>21.260000</td>\n",
       "      <td>41.260000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>42.933333</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.590000</td>\n",
       "      <td>19.066667</td>\n",
       "      <td>46.466667</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>743.666667</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Appliances  lights     T1       RH_1         T2       RH_2     T3  \\\n",
       "10310         150       0  21.50  39.700000  18.700000  43.790000  22.20   \n",
       "1299          360       0  17.39  36.966667  16.390000  36.933333  17.79   \n",
       "4661           60       0  21.20  38.090000  19.166667  38.790000  20.89   \n",
       "19094          70       0  24.00  47.790000  21.700000  50.900000  25.60   \n",
       "4100           50       0  21.89  42.400000  21.260000  41.260000  23.10   \n",
       "\n",
       "            RH_3         T4       RH_4  ...       RH_8         T9       RH_9  \\\n",
       "10310  37.790000  20.463333  36.863333  ...  43.833333  19.790000  41.925000   \n",
       "1299   37.290000  16.290000  36.290000  ...  41.429444  15.600000  35.626667   \n",
       "4661   39.530000  19.390000  39.590000  ...  44.500000  18.500000  41.090000   \n",
       "19094  42.700000  23.500000  46.000000  ...  48.060000  23.290000  49.792857   \n",
       "4100   42.933333  20.500000  43.000000  ...  49.590000  19.066667  46.466667   \n",
       "\n",
       "           T_out  Press_mm_hg     RH_out  Windspeed  Visibility  Tdewpoint  \\\n",
       "10310   5.466667   756.100000  97.000000   2.333333   36.000000   4.966667   \n",
       "1299    0.200000   760.500000  88.500000   2.000000   54.500000  -1.450000   \n",
       "4661    0.416667   741.000000  90.833333   1.833333   23.166667  -0.900000   \n",
       "19094  11.233333   754.200000  96.000000   2.000000   46.333333  10.600000   \n",
       "4100    6.266667   743.666667  80.333333   8.666667   28.666667   3.133333   \n",
       "\n",
       "       is_weekday  \n",
       "10310           1  \n",
       "1299            1  \n",
       "4661            0  \n",
       "19094           1  \n",
       "4100            1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the datetime from the date column and save in a separate dataframe. We'll have to treat this specially in order\n",
    "# to use it in regression.\n",
    "datetime = pd.to_datetime(energy_appliances_full['date'])\n",
    "\n",
    "# Drop the date and last two columns (rv1 and rv2) as they are not useful for regression.\n",
    "energy_appliances = energy_appliances_full.drop(['date', 'rv1', 'rv2'], axis=1)\n",
    "\n",
    "# Create a new column with a binary dummy variable: 1 if the day is a weekday, 0 if it is a weekend\n",
    "energy_appliances['is_weekday'] = (datetime.dt.dayofweek < 5).astype(int)\n",
    "\n",
    "energy_appliances.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "Before designing any machine learning model, we need to set aside the test data. We will use the remaining training data for fitting the model. *It is important to remember that the test data has to be set aside before preprocessing*. \n",
    "\n",
    "Any preprocessing that you do has to be calibrated *only* on the training data, and several key statistics from this preprocessing need to be saved for the test stage. Separating the dataset into training and test before any preprocessing has happened helps us to recreate the real world scenario where we will deploy our system and for which the data will come without any preprocessing.\n",
    "\n",
    "Furthermore, we are going to use *hold-out validation* for validating our predictive model, so we need to further separate the training data into a training set and a validation set.\n",
    "\n",
    "In this step, we will first **shuffle the data**, then split the dataset into a training set, a validation set and a test set: \n",
    "- The training set will have 70% of the total observations,\n",
    "- The validation set will have 15% of the total observations,\n",
    "- The test set will have the remaining 15%. \n",
    "\n",
    "If this doesn't run, check you have correctly initialised the `default_rng()` object with a random seed in **Pre-set up** above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = energy_appliances.shape[0]\n",
    "index = np.arange(ndata)\n",
    "rng.shuffle(index)                        # Permute the indexes \n",
    "Ntrain = np.int64(np.round(0.70*ndata))   # We compute Ntrain, the number of training instances\n",
    "Nval = np.int64(np.round(0.15*ndata))     # We compute Nval, the number of validation instances   \n",
    "Ntest = ndata - Ntrain - Nval             # We compute Ntest, the number of test instances\n",
    "\n",
    "# Split the data into training, validation and test sets\n",
    "# We note that the first column (index 0) is the target variable, what we're trying to predict\n",
    "data_training = energy_appliances.iloc[index[0:Ntrain], 1:].copy() # Select the training data\n",
    "labels_training = energy_appliances.iloc[index[0:Ntrain], 0].copy() # Select the training labels\n",
    "\n",
    "data_val = energy_appliances.iloc[index[Ntrain:Ntrain+Nval], 1:].copy() # Select the validation data\n",
    "labels_val = energy_appliances.iloc[index[Ntrain:Ntrain+Nval], 0].copy() # Select the validation labels\n",
    "\n",
    "data_test = energy_appliances.iloc[index[Ntrain+Nval:ndata], 1:].copy() # Select the test data\n",
    "labels_test = energy_appliances.iloc[index[Ntrain+Nval:ndata], 0].copy() # Select the test labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "It's important to preprocess the data before fitting a model. This includes:\n",
    "- Handling missing values\n",
    "- Scale the data\n",
    "- Encoding categorical or time variables\n",
    "\n",
    "We have already completed the encoding of the datetime variable above, and there are no missing values in this dataset. The only thing left to do is scale the data. Since most of our data is normally distributed, we will use a process called standardization, which scales the data to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Note that we *don't* standardize our categorical variable (`is_weekday`), since it's not a continuous variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>...</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>is_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>1.381400e+04</td>\n",
       "      <td>13814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.851711e-17</td>\n",
       "      <td>1.805418e-15</td>\n",
       "      <td>1.917550e-15</td>\n",
       "      <td>8.142386e-16</td>\n",
       "      <td>8.754479e-16</td>\n",
       "      <td>4.734723e-16</td>\n",
       "      <td>6.357542e-16</td>\n",
       "      <td>1.691358e-15</td>\n",
       "      <td>7.252536e-16</td>\n",
       "      <td>-2.083175e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.682848e-16</td>\n",
       "      <td>-6.460415e-16</td>\n",
       "      <td>5.678581e-16</td>\n",
       "      <td>3.034749e-17</td>\n",
       "      <td>-8.816203e-16</td>\n",
       "      <td>2.880440e-16</td>\n",
       "      <td>2.915159e-16</td>\n",
       "      <td>7.509718e-17</td>\n",
       "      <td>-9.772920e-18</td>\n",
       "      <td>0.723759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.447154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.790362e-01</td>\n",
       "      <td>-3.064273e+00</td>\n",
       "      <td>-3.249020e+00</td>\n",
       "      <td>-1.944176e+00</td>\n",
       "      <td>-4.915504e+00</td>\n",
       "      <td>-2.540808e+00</td>\n",
       "      <td>-3.214333e+00</td>\n",
       "      <td>-2.819270e+00</td>\n",
       "      <td>-2.624373e+00</td>\n",
       "      <td>-2.318942e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.568467e+00</td>\n",
       "      <td>-2.292840e+00</td>\n",
       "      <td>-2.991943e+00</td>\n",
       "      <td>-2.342633e+00</td>\n",
       "      <td>-3.527749e+00</td>\n",
       "      <td>-3.683153e+00</td>\n",
       "      <td>-1.656738e+00</td>\n",
       "      <td>-3.180621e+00</td>\n",
       "      <td>-2.479572e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.790362e-01</td>\n",
       "      <td>-5.713874e-01</td>\n",
       "      <td>-7.318140e-01</td>\n",
       "      <td>-7.011652e-01</td>\n",
       "      <td>-6.217602e-01</td>\n",
       "      <td>-7.505832e-01</td>\n",
       "      <td>-7.146124e-01</td>\n",
       "      <td>-6.383358e-01</td>\n",
       "      <td>-8.084362e-01</td>\n",
       "      <td>-7.154478e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.388630e-01</td>\n",
       "      <td>-7.324267e-01</td>\n",
       "      <td>-7.356199e-01</td>\n",
       "      <td>-7.086760e-01</td>\n",
       "      <td>-6.192774e-01</td>\n",
       "      <td>-6.526885e-01</td>\n",
       "      <td>-8.379663e-01</td>\n",
       "      <td>-7.969012e-01</td>\n",
       "      <td>-6.776429e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.790362e-01</td>\n",
       "      <td>-6.657800e-02</td>\n",
       "      <td>-1.520176e-01</td>\n",
       "      <td>-1.640991e-01</td>\n",
       "      <td>1.756108e-02</td>\n",
       "      <td>-9.732564e-02</td>\n",
       "      <td>-2.136439e-01</td>\n",
       "      <td>-8.740583e-02</td>\n",
       "      <td>-1.385162e-01</td>\n",
       "      <td>-1.195549e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053045e-01</td>\n",
       "      <td>-5.895037e-02</td>\n",
       "      <td>-1.557678e-01</td>\n",
       "      <td>-8.889931e-02</td>\n",
       "      <td>8.129513e-02</td>\n",
       "      <td>2.676747e-01</td>\n",
       "      <td>-1.556567e-01</td>\n",
       "      <td>1.395603e-01</td>\n",
       "      <td>-7.435397e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-4.790362e-01</td>\n",
       "      <td>5.981916e-01</td>\n",
       "      <td>7.029934e-01</td>\n",
       "      <td>5.509747e-01</td>\n",
       "      <td>6.907414e-01</td>\n",
       "      <td>5.293362e-01</td>\n",
       "      <td>7.606324e-01</td>\n",
       "      <td>5.986119e-01</td>\n",
       "      <td>7.179201e-01</td>\n",
       "      <td>5.707523e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.892497e-01</td>\n",
       "      <td>5.417177e-01</td>\n",
       "      <td>6.712079e-01</td>\n",
       "      <td>5.684396e-01</td>\n",
       "      <td>7.329905e-01</td>\n",
       "      <td>7.952000e-01</td>\n",
       "      <td>5.948838e-01</td>\n",
       "      <td>1.395603e-01</td>\n",
       "      <td>6.757881e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.355952e+00</td>\n",
       "      <td>2.837634e+00</td>\n",
       "      <td>4.378953e+00</td>\n",
       "      <td>4.334780e+00</td>\n",
       "      <td>3.841895e+00</td>\n",
       "      <td>3.461183e+00</td>\n",
       "      <td>3.361776e+00</td>\n",
       "      <td>2.571218e+00</td>\n",
       "      <td>2.781904e+00</td>\n",
       "      <td>3.350167e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.057227e+00</td>\n",
       "      <td>2.477755e+00</td>\n",
       "      <td>2.848711e+00</td>\n",
       "      <td>3.498293e+00</td>\n",
       "      <td>2.270093e+00</td>\n",
       "      <td>1.367621e+00</td>\n",
       "      <td>4.074663e+00</td>\n",
       "      <td>2.353015e+00</td>\n",
       "      <td>2.783330e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lights            T1          RH_1            T2          RH_2  \\\n",
       "count  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04   \n",
       "mean   1.851711e-17  1.805418e-15  1.917550e-15  8.142386e-16  8.754479e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.790362e-01 -3.064273e+00 -3.249020e+00 -1.944176e+00 -4.915504e+00   \n",
       "25%   -4.790362e-01 -5.713874e-01 -7.318140e-01 -7.011652e-01 -6.217602e-01   \n",
       "50%   -4.790362e-01 -6.657800e-02 -1.520176e-01 -1.640991e-01  1.756108e-02   \n",
       "75%   -4.790362e-01  5.981916e-01  7.029934e-01  5.509747e-01  6.907414e-01   \n",
       "max    8.355952e+00  2.837634e+00  4.378953e+00  4.334780e+00  3.841895e+00   \n",
       "\n",
       "                 T3          RH_3            T4          RH_4            T5  \\\n",
       "count  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04   \n",
       "mean   4.734723e-16  6.357542e-16  1.691358e-15  7.252536e-16 -2.083175e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.540808e+00 -3.214333e+00 -2.819270e+00 -2.624373e+00 -2.318942e+00   \n",
       "25%   -7.505832e-01 -7.146124e-01 -6.383358e-01 -8.084362e-01 -7.154478e-01   \n",
       "50%   -9.732564e-02 -2.136439e-01 -8.740583e-02 -1.385162e-01 -1.195549e-01   \n",
       "75%    5.293362e-01  7.606324e-01  5.986119e-01  7.179201e-01  5.707523e-01   \n",
       "max    3.461183e+00  3.361776e+00  2.571218e+00  2.781904e+00  3.350167e+00   \n",
       "\n",
       "       ...          RH_8            T9          RH_9         T_out  \\\n",
       "count  ...  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04   \n",
       "mean   ... -3.682848e-16 -6.460415e-16  5.678581e-16  3.034749e-17   \n",
       "std    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min    ... -2.568467e+00 -2.292840e+00 -2.991943e+00 -2.342633e+00   \n",
       "25%    ... -7.388630e-01 -7.324267e-01 -7.356199e-01 -7.086760e-01   \n",
       "50%    ... -1.053045e-01 -5.895037e-02 -1.557678e-01 -8.889931e-02   \n",
       "75%    ...  6.892497e-01  5.417177e-01  6.712079e-01  5.684396e-01   \n",
       "max    ...  3.057227e+00  2.477755e+00  2.848711e+00  3.498293e+00   \n",
       "\n",
       "        Press_mm_hg        RH_out     Windspeed    Visibility     Tdewpoint  \\\n",
       "count  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04  1.381400e+04   \n",
       "mean  -8.816203e-16  2.880440e-16  2.915159e-16  7.509718e-17 -9.772920e-18   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.527749e+00 -3.683153e+00 -1.656738e+00 -3.180621e+00 -2.479572e+00   \n",
       "25%   -6.192774e-01 -6.526885e-01 -8.379663e-01 -7.969012e-01 -6.776429e-01   \n",
       "50%    8.129513e-02  2.676747e-01 -1.556567e-01  1.395603e-01 -7.435397e-02   \n",
       "75%    7.329905e-01  7.952000e-01  5.948838e-01  1.395603e-01  6.757881e-01   \n",
       "max    2.270093e+00  1.367621e+00  4.074663e+00  2.353015e+00  2.783330e+00   \n",
       "\n",
       "         is_weekday  \n",
       "count  13814.000000  \n",
       "mean       0.723759  \n",
       "std        0.447154  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the data to zero mean and unit variance. Note we do NOT apply this to the labels OR to our binary variable!\n",
    "training_means = data_training.mean()\n",
    "training_stds = data_training.std()\n",
    "data_training_standardized = (data_training - training_means) / training_stds\n",
    "# Replace last column (is_weekend) with original binary value - we don't want to standardize this.\n",
    "data_training_standardized['is_weekday'] = data_training['is_weekday']\n",
    "\n",
    "# Let's use describe again: we should see that the mean is 0 (almost - some numerical overflow here) and the standard deviation \n",
    "# is 1 for each feature.\n",
    "data_training_standardized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the preprocessing steps to the validation set as if it were new data: we use the values from the **training** data to standardize the **validation** data. This is important to ensure that the model generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_standardized = (data_val - training_means) / training_stds\n",
    "data_val_standardized['is_weekday'] = data_val['is_weekday'] # don't forget to not standardize this column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training a predictive model\n",
    "\n",
    "We have now split our data into training and validation data and applied relevant preprocessing steps. We are now in a good position to work on developing the prediction model and validating it. We will build a regularised ridge regression model and train it using gradient descent for iterative optimisation. \n",
    "\n",
    "We first organise the dataframes into the vector of targets $\\mathbf{y}$, call it `yTrain`, and the design matrix $\\mathbf{X}$, call it `XTrain`. We will augment `XTrain` with a column of ones: this is the design matrix. We repeat the process for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target vector and design matrix for training data\n",
    "yTrain = np.reshape(labels_training.values, (Ntrain,1)) # The training target labels as a column vector\n",
    "XTrain = np.concatenate((np.ones((Ntrain,1)), data_training_standardized.values), axis=1) # The standardised inputs with an additional column vector  \n",
    "\n",
    "# Do the same for val data\n",
    "yVal = np.reshape(labels_val.values, (Nval,1)) # The validation target labels as a column vector\n",
    "XVal = np.concatenate((np.ones((Nval,1)), data_val_standardized.values), axis=1) # The standardised inputs with an additional column vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal $\\mathbf{w}$ with stochastic gradient descent (5 marks)\n",
    "Now, we will use gradient descent to iteratively compute the value of $\\mathbf{w}_{\\text{new}}$. Instead of using all the training set in `XTrain` and `yTrain` to compute the gradient, use a subset of $S$ instances in `XTrain` and `yTrain`. This is sometimes called *minibatch gradient descent,* where $S$ is the size of the minibatch. \n",
    "\n",
    "You will need to find the best values for three parameters: $\\eta$, the learning rate, $S$, the number of datapoints in the minibatch, and $\\lambda$, the regularisation parameter. We can do this using a grid search over the validation set. You should complete the following tasks:\n",
    "\n",
    "* **Write the optimisation function:** Write a function, `sgd_optimiser`, that takes as input the training data and targets, the learning rate $\\eta$, the minibatch size $S$, the regularisation parameter $\\lambda$, and the number of iterations $T$. The function should return the optimal $\\mathbf{w}$ after the chosen number of iterations. \n",
    "\n",
    "* **Evaluate each set of hyperparameters:** For each value that you have of $\\lambda$, $\\eta$ and $S$ in your grid, use the training set to compute $\\mathbf{w}$ using your `sgd_optimiser` function, and then measure the RMSE using that $\\mathbf{w}$ over the validation data. For the minibatch gradient descent choose to stop the iterative procedure after $500$ iterations. \n",
    "\n",
    "* Choose the values of $\\lambda$, $\\eta$ and $S$ that lead to the lowest RMSE and save them. You will use them at the test stage.\n",
    "\n",
    "When writing these functions, you should avoid using for loops over individual features or samples; that is, you should be able to calculate the gradient, weight updates, and MSE in vectorised form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define the search space by creating a grid of values for the parameters $\\lambda$ and $\\eta$ using `np.logspace` and a grid of values for $S$ using `np.linspace`. Because we need to find three parameters, let's start with five values for each parameter in the grid (see if you can increase it - it may take some time to run). Make sure you understand the meaning of `np.logspace` and `np.linspace`. Notice that you can use negative values for `start` in `np.logspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE GRID OF VALUES FOR LAMBDA, ETA AND S\n",
    "num = 5\n",
    "lambda_vector = np.logspace(-4, -1, num)\n",
    "eta_vector = np.logspace(-5, -2, num)\n",
    "S_vector = np.linspace(10, 200, num, dtype=int) # we want integer values for S (n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda: 0.0005623413251903491, eta: 0.01, S: 105.0, RMSE: 94.4166950240973\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE REGULARISED LINEAR MODEL AND COMPUTE THE RMSE FOR ALL VALUES OF LAMBDA, ETA AND S\n",
    "# note that 'lambda' is a reserved keyword in Python, so we use 'lmbd' instead\n",
    "\n",
    "def sgd_optimiser(X, y, lmbd, eta, S, max_iters=500):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros((n_features, 1))  # Initialize weights\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        \n",
    "        indices = np.random.permutation(n_samples) # Shuffling the indices\n",
    "\n",
    "        \n",
    "        for start in range(0, n_samples, S):   # Looping over the dataset in mini-batches of size S\n",
    "            end = start + S\n",
    "            batch_indices = indices[start:end]  # Getting the current batch\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "\n",
    "            \n",
    "            predictions = np.dot(X_batch, weights) # Computing the predictions\n",
    "\n",
    "            \n",
    "            \n",
    "            gradient = (np.dot(X_batch.T, ((np.dot(X_batch, weights)) - y_batch)) + lmbd * weights) / S        # Computing the gradient\n",
    "            \n",
    "            # Update weights\n",
    "            weights = weights - eta * gradient\n",
    "\n",
    "    \n",
    "    predictions_final = np.dot(X, weights) # Computing RMSE on the training data\n",
    "    rmse = np.sqrt(np.mean((predictions_final - y) ** 2))\n",
    "    return weights, rmse\n",
    "\n",
    "\n",
    "results = [] # Storing RMSE for each combination of parameters\n",
    "\n",
    "#Storing RMSE values for every combination of lambda, eta, and S in a data structure basically like a DataFrame and then save the specific values of lambda, eta, and S that result in the lowest RMSE in : \n",
    "# lmbd = ...\n",
    "# eta = ...\n",
    "# S = ...\n",
    "\n",
    "\n",
    "\n",
    "# I have basically used Grid search here, So Grid searching over lambda, eta, and S\n",
    "for lmbd in lambda_vector:\n",
    "    for eta in eta_vector:\n",
    "        for S in S_vector:\n",
    "            weights, rmse = sgd_optimiser(XTrain, yTrain, lmbd, eta, S)\n",
    "            results.append((lmbd, eta, S, rmse))\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['lambda', 'eta', 'S', 'RMSE']) # Converting results to a DataFrame for easier analysis\n",
    "\n",
    "# Finding the best parameters with minimum RMSE\n",
    "best_result = results_df.loc[results_df['RMSE'].idxmin()]\n",
    "lmbd_opt, eta_opt, S_opt = best_result['lambda'], best_result['eta'], best_result['S']\n",
    "\n",
    "print(f'Optimal lambda: {lmbd_opt}, eta: {eta_opt}, S: {S_opt}, RMSE: {best_result[\"RMSE\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and results reporting (5 marks)\n",
    "\n",
    "We now know the best model, according to the validation data. We will now put together the training data and the validation data and perform the preprocessing as before, this is, impute the missing values and scale the inputs. We will train the model again using the minibatch stochastic gradient descent and finally compute the RMSE over the test data. You should do the following:\n",
    "\n",
    "* **Prepare the data:** In this question we will use the test data. First, combine the original training and validation data and standardize again using the mean and std. from this combined data. Save the values from this preprocessing step. Use the saved values to preprocess the test data, similarly to how we used the values from training data to preprocess the validation data. Before training and inference, don't forget to add the column of ones to the data to create the design matrix.\n",
    "\n",
    "* **Re-train your model** on the full training set, using the optimal values of $\\lambda$, $\\eta$ and $S$.\n",
    "\n",
    "* **Run your model** on the test data using the optimal values of of $\\lambda$, $\\eta$ and $S$, and report the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.78052689 -1.24646795 ...  2.03581257 -1.16165914\n",
      "   1.        ]\n",
      " [ 1.         -0.47994852  1.9293505  ...  1.2151055   2.0219916\n",
      "   1.        ]\n",
      " [ 1.         -0.47994852  1.56123009 ...  0.13969625  1.34944538\n",
      "   1.        ]\n",
      " ...\n",
      " [ 1.         -0.47994852 -0.19202135 ... -0.49705923  1.13454896\n",
      "   1.        ]\n",
      " [ 1.         -0.47994852  0.74387799 ... -0.32725777  1.05097813\n",
      "   1.        ]\n",
      " [ 1.         -0.47994852 -0.25441464 ...  0.13969625 -0.31003257\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Combine the training and validation data into a single final training set\n",
    "data_training_full = pd.concat([data_training, data_val])\n",
    "labels_training_full = pd.concat([labels_training, labels_val])\n",
    "\n",
    "# Standardize the new training set\n",
    "training_means_full = data_training_full.mean()\n",
    "training_stds_full = data_training_full.std()\n",
    "data_training_full_standardized = (data_training_full - training_means_full) / training_stds_full\n",
    "data_training_full_standardized['is_weekday'] = data_training_full['is_weekday']\n",
    "\n",
    "\n",
    "# Create the new design matrix and target vector for the full training set\n",
    "yTrain_full = np.reshape(labels_training_full.values, (data_training_full.shape[0], 1))\n",
    "XTrain_full = np.concatenate((np.ones((data_training_full.shape[0], 1)), data_training_full_standardized.values), axis=1)\n",
    "print(XTrain_full)\n",
    "\n",
    "\n",
    "# Preprocess the test data and create the design matrix and target vector\n",
    "data_test_standardized = (data_test - training_means) / training_stds\n",
    "data_test_standardized['is_weekday'] = data_test['is_weekday']\n",
    "yTest = np.reshape(labels_test.values, (data_test.shape[0], 1))\n",
    "XTest = np.concatenate((np.ones((data_test.shape[0], 1)), data_test_standardized.values), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 94.04640003146241\n"
     ]
    }
   ],
   "source": [
    "# Train the regularised linear model and compute the RMSE for the values of gamma, eta and S over the test data\n",
    "final_weights, final_rmse = sgd_optimiser(XTrain_full, yTrain_full, lmbd_opt, eta_opt, int(S_opt))\n",
    "\n",
    "# Compute RMSE on the test data\n",
    "predictions_test = np.dot(XTest, final_weights)\n",
    "test_rmse = np.sqrt(np.mean((predictions_test - yTest) ** 2))\n",
    "\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
